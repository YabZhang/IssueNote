### ## `async/await` in rust

[origin video url](https://www.youtube.com/watch?v=lJ3NC-R3gSI)

* `native thread` vs `green thread` 

* `Callback`, `Future`  and `Promise`
* `async/await` in rust | rust has no gc



## `CPU` Caches



[origin url](https://software.rajivprab.com/2018/04/29/myths-programmers-believe-about-cpu-caches/)

> For one thing, many of the concepts learnt in cache-coherency are directly applicable to [distributed-system-architecture](https://en.wikipedia.org/wiki/Distributed_computing) and [database-isolation-levels](https://en.wikipedia.org/wiki/Isolation_(database_systems)#Isolation_levels) as well. For instance, understanding how coherency is implemented in hardware caches, can help in better understanding [strong-vs-eventual consistency](https://hackernoon.com/eventual-vs-strong-consistency-in-distributed-databases-282fdad37cf7). It can spur ideas on how to better enforce consistency in distributed systems, using the same research and principles applied in hardware.



Cache-Coherent: 缓存关联, 例如：从不同L1的共享缓存必须读出一致的数值；

[`MESI 协议`](https://en.wikipedia.org/wiki/MESI_protocol): 保证缓存一致性协议；和应用层的缓存更新逻辑极为相似！



Keyword `volatile` in Java (or languages like Java):

>That’s a very complicated question that’s [better answered elsewhere](https://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html), but let me just drop one partial hint. Data that’s read into [CPU registers](https://en.wikipedia.org/wiki/Processor_register), is *not* kept in sync with data in cache/memory. The software compiler makes all sorts of optimizations when it comes to [loading data into registers, writing it back to the cache](https://www.inf.ed.ac.uk/teaching/courses/copt/lecture-7.pdf), and even [reordering of instructions](https://stackoverflow.com/questions/22106843/gccs-reordering-of-read-write-instructions). This is all done assuming that the code will be run single-threaded. Hence why any data that is at risk of race-conditions, needs to be manually protected through concurrency algorithms and language constructs such as atomics and volatiles.

> In the case of Java volatiles, part of the solution is to force all reads/writes to bypass the local registers, and [immediately trigger cache reads/writes instead](https://stackoverflow.com/questions/4633866/is-volatile-expensive). As soon as the data is read/written to the L1 cache, the hardware-coherency protocol takes over and provides guaranteed coherency across all global threads. Thus ensuring that if multiple threads are reading/writing to the same variable, they are all kept in sync with one another. And this is how you can achieve inter-thread coordination in as little as 1ns.